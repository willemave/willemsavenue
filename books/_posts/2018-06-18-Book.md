---
layout: post
---
Book: the book of why

No mathematical equations for Cause and Effect. Statistics pushed this aside, correlation is not causation. Path Analysis starts to help here. So does Casual Diagrams.

Data is dumb. Doesn't tell us why. Causal modes can help machines tell us what they are doing and why.

Query, data, assumptions = inherence engine. 

Counterfactual are key to why. Data can not show cause and effect unless done by controller experiments.

## Ladder of causation
Things we can imagine are the bedrock of causation (from Sapiens). Modularity, swapping variables and recalculating outcomes. Observe => doing => imagining. Last step is creating theories on cause / effect of tools for example.

The ladder: 
Association. "What if I see", regressions.
Intervention. "Changing what is". A/B testing is one way. 
Counterfactual. 

Causal models are much more resilient then probability distributions. Cause happens when intervention or imagination happen.

La-QAplases theorem, central limit theory, sum of random decisions will end up to a normal distribution. Price is Right balls.



Regression to mean is not a causal relationship. Ie sophomore slump. 

Correlation coefficient detrrmines how two variables interact and of they revert to a mean, can plot these and look at slope.

## causal inference

Khaneman: success = talent + luck. More success is a but more talent and lots of luck.

Correlation killed causation.

Causation is not to prove X means Y, or to define X by studying Y.

Statistics is methods of reduction of data.


Bayesian thinking started to incorporate causal thinking. Prior Belief + New Evidence = Revised Belief

## Bayesian from evidence to cause

Bayesian networks are from cause to effect, or induction from evidence to hypothesis (and then cause).

Belief network propagation is implementation of baysian network.

Core idea is how much evidence do you need to go from probable to improbable, ie "dead people stay dead".

Bayes rule helps the scientific method in organic outcomes. Inverse probabilities are crazy, re mammograms and the psychological harm they can cause. Bayes is subjective, or if you have history of cancer percentage goes up.

## Bayes networks 1
Child to parent is updating with likelyhood ration. Parent to childen update with conditional probabilities.

Inverse probabilities are the simplest Bayesian networks. Two boxes one connection.

Conditional independence. explain away syndrome.

Chains, forks and Colliders. Explain away and collider bias.

Sparse networks are necessary as baysian calculation grows at 2^n

Bayesian networks are just probability tables. 

Arrows in causal diagrams are outcomes of hypotheticals, if you can modify something and another changes then there is an arrow. 

Bayesian networks allow you to test relations based on correlations in data,A-B, A-C, can test of any cortisone between A and C.

## confounding variables
What should you control for? Mixing variables.

Statistics has trouble with interventions or intention to do something, however this is key to causal relationships.

Randomization solves for confounding variables. Confounding variables are discrepancies between p(X|Y) and p(X do Y).

Back door principle - removing any causal lines that affect X. Sometimes controlling for a variable a can make it a confounder.


Hmmm QAMoney and capatilism can super charge comforts
